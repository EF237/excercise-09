---
title: "excercise-09"
author: "Joyradyn"
format: html
editor: visual
---

## Step 1

Load data set and do a quick exploratory data analysis.You can view the five-number summary (median, minimum, maximum, first quartile, and third quartile), along with the mean and standard deviation, for each quantitative variable with the `skim()` function.

```{r, message=FALSE, warning=FALSE}
library(tidyverse)

f <- "https://raw.githubusercontent.com/difiore/ada-datasets/main/Street_et_al_2017.csv"
  
d <- read_csv(f, col_names = TRUE)

library(skimr)

skim(d)
```

## Step 2

Plot brain size (ECV) as a function of social group size (Group_size), longevity (Longevity), juvenile period length (Weaning), and reproductive lifespan (Repro_lifespan).

```{r, message=FALSE, warning=FALSE}
par(mfrow = c(2,2))
  
 # Group_size
plot(d$Group_size, d$ECV, main = "ECV vs Group Size",
     xlab = "Group Size", ylab = "ECV")

 # Longevity
plot(d$Longevity, d$ECV, main = "ECV vs Longevity",
     xlab = "Longevity", ylab = "ECV")

  # Weaning
plot(d$Weaning, d$ECV, main = "ECV vs Weaning Period",
     xlab = "Weaning Period", ylab = "ECV")

  # Reproductive Lifespan
plot(d$Repro_lifespan, d$ECV, main = "ECV vs Reproductive Lifespan",
     xlab = "Reproductive Lifespan", ylab = "ECV")
```

## Step 3

By hand derive the ordinary least squares regression coefficients Beta1 and Beta0 for ECV as a function of social group size.

```{r, message=FALSE, warning=FALSE}
EG <- na.omit(d[, c("ECV", "Group_size")])

  # beta 1 by hand (3 options)
(beta1 <- sum((EG$ECV - mean(EG$ECV)) * (EG$Group_size - mean(EG$Group_size)))/sum((EG$Group_size - mean(EG$Group_size))^2))
#or
(beta1 <- cov(EG$Group_size, EG$ECV)/var(EG$Group_size))
#or
(beta1 <- cor(EG$Group_size, EG$ECV) * (sd(EG$ECV)/sd(EG$Group_size)))

  # beta0 by hand
(beta0 <- mean(EG$ECV) - beta1 * mean(EG$Group_size))
```

## Step 4

Confirm your results via `lm()` function.

```{r, message=FALSE, warning=FALSE}
(m <- lm(ECV ~ Group_size, data = EG))

summary(m)

par(mfrow = c(2,2))

plot(m)
```

*We can confirm that our hand-derived functions are correct because the `lm()` function produces the same values for both Beta1 and Beta0.*

## Step 5

Repeat the analysis above for three different major radiations of primates - “catarrhines”, “platyrrhines”, and “strepsirhines”) separately.

```{r, message=FALSE, warning=FALSE}
  # Catarrhini
c = d |>
  filter (Taxonomic_group == "Catarrhini")

(c.m <- lm(ECV ~ Group_size, data = c))

summary(c.m)

par(mfrow = c(2,2))

plot(c.m)

  # Platyrrhini
p = d |>
  filter (Taxonomic_group == "Platyrrhini")

(p.m <- lm(ECV ~ Group_size, data = p))

summary(p.m)

par(mfrow = c(2,2))

plot(p.m)

  # Strepsirhini
s = d |>
  filter (Taxonomic_group == "Strepsirhini")

(s.m <- lm(ECV ~ Group_size, data = s))

summary(s.m)

par(mfrow = c(2,2))

plot(s.m)
```

# Do your regression coefficients differ among groups? How might you determine this?

Yes, it changes for each group, as shown in the summary and by comparing the graphs.

## Step 6

For your first regression of ECV on social group size, calculate the standard error for the slope coefficient, the 95% CI, and the p value associated with this coefficient by hand. Also extract this same information from the results of running the `lm()` function. Note that Beta1 & Beta0 where both previously created by hand in Step 3.

# 1. Standard error for the slope coefficient

```{r, message=FALSE, warning=FALSE}
X <- EG$Group_size
Y <- EG$ECV
n <- length(X)
X_mean <- mean(X)
Y_mean <- mean(Y)
predict <- beta0 + beta1 * X
residuals <- Y - predict


(stderror <- sqrt((sum(residuals^2)) / (n - 2)) / sqrt(sum((X - X_mean)^2)))
```

# 2. 95% CI

```{r, message=FALSE, warning=FALSE}
t_critical <- qt(0.975, (n-2)) 

(lower <- beta1 - t_critical * stderror)
(upper <- beta1 + t_critical * stderror)
```

# 3. p value associated with this coefficient

```{r, message=FALSE, warning=FALSE}
t_stat <- beta1 / stderror

(p <- 2 * (1 - pt(abs(t_stat), (n-2))))
```

# Confirmation

```{r, message=FALSE, warning=FALSE}
m2 <- lm(ECV ~ Group_size, data = EG)

# Standard error for the slope coefficient
summary(m)$coefficients["Group_size", "Std. Error"]

# 95% CI
confint(m)

# p value associated with this coefficient
summary(m)$coefficients["Group_size", "Pr(>|t|)"]
```

## Step 7

Use a permutation approach with 1000 permutations to generate a null sampling distribution for the slope coefficient.

```{r, message=FALSE, warning=FALSE}
library(broom)
library(infer)

alpha <- 0.05
confidence_level <- 1 - alpha
p_lower <- alpha/2
p_upper <- 1 - (alpha/2)
degrees_of_freedom <- nrow(EG) - 2
critical_value <- qt(p_upper, df = degrees_of_freedom)

original.slope <- lm(data = EG, ECV ~ Group_size) |>
  tidy(conf.int = TRUE, conf.level = confidence_level) |>
  mutate(lower = estimate - std.error * critical_value, upper = estimate + std.error *
    critical_value) |>
  filter(term == "Group_size")

permuted.slope <- EG |>
specify(ECV ~ Group_size) |>
hypothesize(null = "independence") |>
generate(reps = 1000, type = "permute") |>
calculate(stat = "slope")

permuted.slope.summary <- permuted.slope |>
  summarize(estimate = mean(stat), std.error = sd(stat), lower = estimate - std.error *
    critical_value, upper = estimate + std.error * critical_value, perm.lower = quantile(stat,
    p_lower), perm.upper = quantile(stat, p_upper))

get_ci(permuted.slope, level = 1 - alpha, type = "percentile")

get_ci(permuted.slope, level = 1 - alpha, type = "se", point_estimate = pull(permuted.slope.summary,
    estimate))

p.value <- permuted.slope |>
  mutate(abs_stat = abs(stat)) |>
  summarize(estimate = mean(abs_stat >= abs(pull(original.slope, estimate))))

p.value

(p.value <- permuted.slope |>
    get_p_value(obs_stat = original.slope$estimate, direction = "two_sided"))
```

# What is it that you need to permute? What is the p value associated with your original slope coefficient?

We permute the brain size. The p value for the original slope is 7.26e-11 while the permuted p value is 0.

## Step 8

Use bootstrapping to generate a 95% CI for your estimate of the slope coefficient using both the quantile method and the theory-based method (i.e., using the standard deviation of the bootstrapped sampling distribution as an estimate of the standard error).

```{r, message=FALSE, warning=FALSE}
boot.slope <- EG |>
  specify(ECV ~ Group_size) |>
  generate(reps = 1000, type = "bootstrap") |>
  calculate(stat = "slope")

boot.slope.summary <- boot.slope |>
  summarize(estimate = mean(stat), std.error = sd(stat), lower = estimate - std.error *
    critical_value, upper = estimate + std.error * critical_value, boot.lower = quantile(stat,
    p_lower), boot.upper = quantile(stat, p_upper))

#Quantile Method
boot.slope.summary

# Percentile Method
(CI.percentile <- get_ci(boot.slope, level = 1 - alpha, type = "percentile"))

# Theory Method
(CI.theory <- get_ci(boot.slope, level = 1 - alpha, type = "se", point_estimate = pull(boot.slope.summary,
    estimate)))
```

# Do these CIs suggest that your slope coefficient is different from zero?

Yes, these CIs suggest that the slope coefficient is different from zero.
